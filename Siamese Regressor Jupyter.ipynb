{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "92_YFxI0IqT3"
   },
   "source": [
    "In the beginning there was the repo, the csv file floated over the data, we took it, made it into a train + test split and passed it on to the next segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "XPZ9mdB1KRjm",
    "outputId": "58ab8e9f-7eb4-47e0-94bb-63bd299a8182"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'pestilence' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://mekaneeky:splashscreen123!@github.com/mekaneeky/pestilence.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "6QCoQ5gmIqT-",
    "outputId": "76029416-1acb-4dd6-e2f3-3a616bb231f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Training set size: 4826\n",
      "Validation set size: 604\n",
      "Test set size: 603\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def labels_to_numbers(df_column):\n",
    "    numbers_dict = {value:number for (number, value) in enumerate(df_column.unique())}\n",
    "    return df_column.apply( lambda x : numbers_dict[x])\n",
    "\n",
    "\n",
    "path_to_csv = \"pestilence/training/training_final_siamese.csv\"\n",
    "path_to_csv_test = \"pestilence/testing/testing_final_siamese.csv\"\n",
    "use_val = True\n",
    "use_test_from_train = False\n",
    "\n",
    "init_df = pd.read_csv(path_to_csv, index_col=\"id\")\n",
    "init_df = init_df.astype({'similarity':'str'})\n",
    "init_df = init_df.drop([1058, 2775])\n",
    "\n",
    "if use_test_from_train == False:\n",
    "    test_df = pd.read_csv(path_to_csv_test, index_col=\"id\")\n",
    "    test_df = test_df.astype({'similarity':'str'})\n",
    "\n",
    "train_percentage = 0.6\n",
    "val_percentage = 0.3\n",
    "test_percentage = 0.1\n",
    "\n",
    "if use_val == True and use_test_from_train == True:\n",
    "    train_cutoff_index = int(len(init_df) * train_percentage)\n",
    "    train_df = init_df[:train_cutoff_index]\n",
    "    test_df = init_df[train_cutoff_index:]\n",
    "    val_cutoff_index = int(len(test_df) * val_percentage)\n",
    "    val_df = test_df[val_cutoff_index:]\n",
    "    test_df = test_df[:val_cutoff_index]\n",
    "    #val_df.dis_label_class = labels_to_numbers(val_df.dis_label_class)\n",
    "    #val_label_class = to_categorical(val_df.dis_label_class.values, num_classes=len(val_df.dis_label_class.unique()))\n",
    "    #val_similarity = to_categorical(val_df.similarity.values, num_classes=len(val_df.similarity.unique()))\n",
    "\n",
    "\n",
    "elif use_val == True and use_test_from_train == False:\n",
    "    val_cutoff_index = int(len(init_df) * val_percentage)\n",
    "    train_df = init_df[:val_cutoff_index]\n",
    "    val_df = init_df[val_cutoff_index:]\n",
    "\n",
    "    ## test\n",
    "\n",
    "    \n",
    "elif use_val == False and use_test_from_train == True:\n",
    "    val_cutoff_index = int(len(init_df) * train_percentage)\n",
    "    train_df = init_df[:val_cutoff_index]\n",
    "    val_df = init_df[val_cutoff_index:]\n",
    "\n",
    "    ## test\n",
    "elif use_val == False and use_test_from_train == False:\n",
    "    ## No val or test from train\n",
    "    train_df = init_df\n",
    "\n",
    "print(len(train_df.dis_label_class.unique()))\n",
    "\n",
    "train_df.cpp_norm_reg = (train_df.cpp_norm_reg - train_df.cpp_norm_reg.mean())/train_df.cpp_norm_reg.std()\n",
    "train_df.poverty_reg = (train_df.poverty_reg - train_df.poverty_reg.mean())/train_df.poverty_reg.std()\n",
    "if use_val:\n",
    "    val_df.cpp_norm_reg = (val_df.cpp_norm_reg - train_df.cpp_norm_reg.mean())/train_df.cpp_norm_reg.std()\n",
    "    val_df.poverty_reg = (val_df.poverty_reg - train_df.poverty_reg.mean())/train_df.poverty_reg.std()\n",
    "test_df.cpp_norm_reg = (test_df.cpp_norm_reg - train_df.cpp_norm_reg.mean())/train_df.cpp_norm_reg.std()\n",
    "test_df.poverty_reg = (test_df.poverty_reg - train_df.poverty_reg.mean())/train_df.poverty_reg.std()\n",
    "\n",
    "print(\"Training set size: \" + str(len(train_df)))\n",
    "if use_val:\n",
    "    print(\"Validation set size: \" + str(len(val_df)))\n",
    "print(\"Test set size: \" + str(len(test_df)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TENQm5q1IqUP"
   },
   "source": [
    "Now we have our training, testing and possibly validation sets. Now we need to create a generator to pass the data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "RCcDMfbUIqUS",
    "outputId": "632286d0-784e-48a6-b62f-53654d833460"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4826 validated image filenames belonging to 3 classes.\n",
      "Found 604 validated image filenames belonging to 3 classes.\n",
      "Found 603 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_dir = \"pestilence/training\"\n",
    "if use_test_from_train == False:\n",
    "    test_dir = \"pestilence/testing\"\n",
    "else:\n",
    "    test_dir = data_dir\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_previous_datagen = ImageDataGenerator(rescale=1./255)\n",
    "if use_val:\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    val_previous_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_previous_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "def train_gen( batch_size=batch_size, regression_columns = [\"cpp_norm_reg\", \"poverty_reg\"]):\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_dataframe(train_df, directory=data_dir, x_col='filename_housing', y_col='similarity', \n",
    "                    target_size=(224, 224), color_mode='rgb', classes=None, \n",
    "                    class_mode='binary', batch_size=batch_size, shuffle=False, seed=500, \n",
    "                    save_to_dir=None, save_prefix='', save_format='png', subset=None, \n",
    "                    interpolation='nearest', drop_duplicates=True)\n",
    "    \n",
    "    train_previous_generator = train_previous_datagen.flow_from_dataframe(train_df, directory=data_dir, x_col='filename_housing_previous', y_col=regression_columns, \n",
    "                    target_size=(224, 224), color_mode='rgb', classes=None, \n",
    "                    class_mode='other', batch_size=batch_size, shuffle=False, seed=500, \n",
    "                    save_to_dir=None, save_prefix='', save_format='png', subset=None, \n",
    "                    interpolation='nearest', drop_duplicates=True)\n",
    "    while True:\n",
    "      x_train = train_generator.next()\n",
    "      x_previous_train = train_previous_generator.next()\n",
    "      yield [x_previous_train[0], x_train[0] ], [x_previous_train[1], x_train[1]]\n",
    "    \n",
    "if use_val:\n",
    "  def val_gen( batch_size= batch_size, regression_columns = [\"cpp_norm_reg\", \"poverty_reg\"]):\n",
    "\n",
    "      val_generator = val_datagen.flow_from_dataframe(val_df, directory=data_dir, x_col='filename_housing', y_col='similarity', \n",
    "                      target_size=(224, 224), color_mode='rgb', classes=None, \n",
    "                      class_mode='binary', batch_size=batch_size, shuffle=False, seed=500, \n",
    "                      save_to_dir=None, save_prefix='', save_format='png', subset=None, \n",
    "                      interpolation='nearest', drop_duplicates=True)\n",
    "\n",
    "      val_previous_generator = val_previous_datagen.flow_from_dataframe(val_df, directory=data_dir, x_col='filename_housing_previous', y_col=regression_columns, \n",
    "                      target_size=(224, 224), color_mode='rgb', classes=None, \n",
    "                      class_mode='other', batch_size=batch_size, shuffle=False, seed=500, \n",
    "                      save_to_dir=None, save_prefix='', save_format='png', subset=None, \n",
    "                      interpolation='nearest', drop_duplicates=False)\n",
    "      while True:\n",
    "        x_val = val_generator.next()\n",
    "        x_previous_val = val_previous_generator.next()\n",
    "        yield [x_previous_val[0], x_val[0] ], [x_previous_val[1], x_val[1]]\n",
    "      \n",
    "def test_gen( batch_size=batch_size, regression_columns = [\"cpp_norm_reg\", \"poverty_reg\"]):\n",
    "    \n",
    "    test_generator = test_datagen.flow_from_dataframe(test_df, directory=test_dir, x_col='filename_housing', y_col='similarity', \n",
    "                    target_size=(224, 224), color_mode='rgb', classes=None, \n",
    "                    class_mode='binary', batch_size=batch_size, shuffle=False, seed=500, \n",
    "                    save_to_dir=None, save_prefix='', save_format='png', subset=None, \n",
    "                    interpolation='nearest', drop_duplicates=False)\n",
    "    \n",
    "    test_previous_generator = test_previous_datagen.flow_from_dataframe(test_df, directory=test_dir, x_col='filename_housing_previous', y_col=regression_columns, \n",
    "                    target_size=(224, 224), color_mode='rgb', classes=None, \n",
    "                    class_mode='other', batch_size=batch_size, shuffle=False, seed=500, \n",
    "                    save_to_dir=None, save_prefix='', save_format='png', subset=None, \n",
    "                    interpolation='nearest', drop_duplicates=False)\n",
    "    while True:\n",
    "      x_test = test_generator.next()\n",
    "      x_previous_test = test_previous_generator.next()\n",
    "      yield [x_previous_test[0], x_test[0] ], [x_previous_test[1], x_test[1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EHYhFCa-IqUd"
   },
   "source": [
    "Now we proceed to decapitate the model, and retrain its head on the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5308
    },
    "colab_type": "code",
    "id": "xIhS3bhwIqUg",
    "outputId": "90c49b49-c9f7-44f0-e749-9484f3dfbea2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0620 14:12:21.177696 140233942390656 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0620 14:12:21.183108 140233942390656 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0620 14:12:21.208551 140233942390656 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0620 14:12:21.209724 140233942390656 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0620 14:12:22.047536 140233942390656 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0620 14:12:22.557924 140233942390656 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 111, 111, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 111, 111, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 111, 111, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 109, 109, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 109, 109, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 109, 109, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 109, 109, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 109, 109, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 109, 109, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 109, 109, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 109, 109, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 55, 55, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 55, 55, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 55, 55, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 55, 55, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 55, 55, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 55, 55, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 55, 55, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 55, 55, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 55, 55, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 55, 55, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 256)  32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 28, 28, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 28, 28, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 28, 28, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 28, 28, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 28, 28, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 28, 28, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 28, 28, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 28, 28, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 14, 14, 728)  186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 14, 14, 728)  2912        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 14, 14, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 14, 14, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 14, 14, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 14, 14, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 14, 14, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 14, 14, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 14, 14, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 14, 14, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 14, 14, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 14, 14, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 14, 14, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 14, 14, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 14, 14, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 14, 14, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 14, 14, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 14, 14, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 14, 14, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 14, 14, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 14, 14, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 14, 14, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 14, 14, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 14, 14, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 14, 14, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 14, 14, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 14, 14, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 14, 14, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 14, 14, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 14, 14, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 7, 7, 1024)   745472      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 7, 7, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 7, 7, 1024)   4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 7, 7, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 7, 7, 1536)   1582080     add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 7, 7, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 7, 7, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 7, 7, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 7, 7, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 7, 7, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 20,861,480\n",
      "Trainable params: 20,806,952\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.xception import Xception\n",
    "\n",
    "#xception_weights_path = \"/home/leila/Code/siamese_traffic_density/pretrained/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "xception_conv_base = Xception(include_top=False, weights=\"imagenet\", input_tensor=None, input_shape=(224, 224, 3), pooling=None, classes=None)\n",
    "xception_conv_base.summary()\n",
    "#xception_conv_base.load_weights(xception_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "L3gBkBF0IqUp",
    "outputId": "6b85aaaa-1baa-4d8c-d359-8ed53e766463"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0620 14:12:30.614939 140233942390656 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Lambda, Input, Multiply, Dot, Add, Concatenate, Average\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def initialize_weights(shape, name=None):\n",
    "    \"\"\"\n",
    "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "        suggests to initialize CNN layer weights with mean as 0.0 and standard deviation of 0.01\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc = 0.0, scale = 1e-2, size = shape)\n",
    "\n",
    "def initialize_bias(shape, name=None):\n",
    "    \"\"\"\n",
    "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "        suggests to initialize CNN layer bias with mean as 0.5 and standard deviation of 0.01\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)\n",
    "  \n",
    "\n",
    "current_input = Input(shape= (224, 224, 3), name=\"current_input\")\n",
    "previous_input = Input(shape= (224, 224, 3), name=\"previous_input\")\n",
    "\n",
    "xception_model_embeddings_current = xception_conv_base (current_input)\n",
    "xception_model_embeddings_previous = xception_conv_base (previous_input)\n",
    "\n",
    "## Add necessary max pooling and convs mentioned in the original thesis\n",
    "\n",
    "pre_L1_flatten = Flatten( name=\"flatten\")(xception_model_embeddings_current)\n",
    "pre_L1_flatten_previous = Flatten(name=\"previous_flatten\")(xception_model_embeddings_previous)\n",
    "\n",
    "L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]), name=\"l1\")\n",
    "L1_distance = L1_layer([pre_L1_flatten_previous, pre_L1_flatten])\n",
    "similarity_prediction = Dense(1,activation='sigmoid',bias_initializer=initialize_bias, name=\"similarity_pred\")(L1_distance)\n",
    "#similarity_prediction_cat = Lambda(K.one_hot,arguments={'num_classes': 2},output_shape=(2,))(similarity_prediction)\n",
    "#similarity_prediction_cat = Dense(2, activation=\"softmax\", name=\"a7a_layer\") (similarity_prediction)\n",
    "#Here we try adding #should I add the functional version and should I include the previous embeddings as inputs\n",
    "diffrentiable_conditional_add = Lambda( lambda x:K.switch(K.greater_equal(x,0.5),Add(name=\"add_inner\")([xception_model_embeddings_current, xception_model_embeddings_previous]) ,xception_model_embeddings_current ), name=\"add_conditional\")(similarity_prediction)\n",
    "#diffrentiable_conditional_dot = Lambda( lambda x:K.where(x>=0.5, Dot()([xception_model_embeddings_current, xception_model_embeddings_previous]), xception_model_embeddings_current))(similarity_prediction)\n",
    "diffrentiable_conditional_multiply = Lambda( lambda x:K.switch(x>=0.5,Multiply()([xception_model_embeddings_current, xception_model_embeddings_previous]) , xception_model_embeddings_current))(similarity_prediction)\n",
    "diffrentiable_conditional_average = Lambda( lambda x:K.switch(x>=0.5,Average()([xception_model_embeddings_current, xception_model_embeddings_previous]) , xception_model_embeddings_current))(similarity_prediction)\n",
    "#diffrentiable_conidtional_concatenate = Lambda( lambda x:K.where(x>=0.5,Concatenate()([xception_model_embeddings_current, xception_model_embeddings_previous])  , xception_model_embeddings_current))(similarity_prediction)\n",
    "\n",
    "#Here we try convolution\n",
    "\n",
    "#Be sure to initialize a different one with var input sizes for concat version\n",
    "#predictor_convolution = xception_conv_final_predictor(diffrentiable_conditional_add)\n",
    "final_predictor_1 = Flatten() (diffrentiable_conditional_add)\n",
    "final_predictor_2 = Dense(1024, activation='relu') (final_predictor_1)\n",
    "final_predictor_3 = Dense(512, activation='relu') (final_predictor_2)\n",
    "final_predictor_4 = Dense(256, activation='relu') (final_predictor_3)\n",
    "final_prediction = Dense(2, name=\"final_pred\") (final_predictor_4)\n",
    "\n",
    "siamese_model_full = Model(inputs=[current_input, previous_input], outputs=[ final_prediction, similarity_prediction])\n",
    "\n",
    "losses = {\n",
    "    'similarity':'binary_crossentropy',\n",
    "    'final_pred':'mae'\n",
    "}\n",
    "\n",
    "metrics = {\n",
    "    'similarity':'accuracy',\n",
    "    'final_pred':['mae', 'mse']\n",
    "}\n",
    "\n",
    "siamese_model_full.compile(optimizer=\"adagrad\",loss=losses, metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "colab_type": "code",
    "id": "0mx-rvXwIqUv",
    "outputId": "58ba1c70-91b3-4287-8f40-d838fb081bab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "151/151 [==============================] - 108s 713ms/step - loss: 1.0086 - acc: 0.4701 - val_loss: 0.8992 - val_acc: 0.8444\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.89919, saving model to weights-improvement---01-0.90.hdf5\n",
      "Epoch 2/50\n",
      "151/151 [==============================] - 106s 704ms/step - loss: 1.0087 - acc: 0.4668 - val_loss: 0.9519 - val_acc: 0.8245\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.89919\n",
      "Epoch 3/50\n",
      "151/151 [==============================] - 106s 703ms/step - loss: 1.0028 - acc: 0.4705 - val_loss: 0.8914 - val_acc: 0.8377\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.89919 to 0.89136, saving model to weights-improvement---03-0.89.hdf5\n",
      "Epoch 4/50\n",
      "151/151 [==============================] - 106s 703ms/step - loss: 1.0124 - acc: 0.4697 - val_loss: 0.9143 - val_acc: 0.8444\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.89136\n",
      "Epoch 5/50\n",
      "151/151 [==============================] - 106s 704ms/step - loss: 1.0404 - acc: 0.4716 - val_loss: 1.0711 - val_acc: 0.7947\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.89136\n",
      "Epoch 6/50\n",
      "151/151 [==============================] - 107s 706ms/step - loss: 1.0057 - acc: 0.4745 - val_loss: 0.9052 - val_acc: 0.8179\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.89136\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from math import ceil\n",
    "\n",
    "training_steps = ceil(4826/32)\n",
    "validation_steps = ceil(604/32)\n",
    "pre_file_path = \"siamese-regression-\"\n",
    "post_file_path = \"--{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "filepath= pre_file_path + post_file_path\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=1, mode='auto', baseline=None, restore_best_weights=True)\n",
    "callbacks_list = [stopping, checkpoint]\n",
    "\n",
    "xception_history = siamese_model_full.fit_generator(train_gen(), steps_per_epoch=training_steps, epochs=50, verbose=1, callbacks=callbacks_list, validation_data=val_gen(),\n",
    "                             validation_steps = validation_steps,class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, \n",
    "                             shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9u_aOmtbIqU3",
    "outputId": "a1048ef4-c880-4422-bd75-7c13dc0f9149"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = xcpetion_history.history['loss']\n",
    "val_loss = xcpetion_history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "am-fhDAoIqVC"
   },
   "outputs": [],
   "source": [
    "index = train_df['similarity'].index[train_df['similarity'].apply(np.isnan)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tnf9WqtWIqVN",
    "outputId": "519b3b4d-e167-417b-f979-b0468f9b0884"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1059, 2776], dtype='int64', name='id')"
      ]
     },
     "execution_count": 101,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dNucp1rxIqVe"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"pestilence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "yFILNspidtDA",
    "outputId": "daee5fd0-3657-4704-a8ae-8162381414b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master e423aaf] added weights of classifier model\n",
      " 1 file changed, 0 insertions(+), 0 deletions(-)\n",
      " create mode 100644 class-weights-improvement---03-0.89.hdf5\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"added weights of classifier model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "KIAplesIepqu",
    "outputId": "a5b1db49-1aac-41fb-bbef-bb77978d197b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git: 'reset~' is not a git command. See 'git --help'.\n",
      "\n",
      "The most similar command is\n",
      "\treset\n"
     ]
    }
   ],
   "source": [
    "!git config --global user.email \"alizawahry1@gmail.com\"\n",
    "!git config --global user.name \"mekaneeky\"\n",
    "!git reset~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "G_DI83wcfHSO",
    "outputId": "c0ba8d1a-6513-4bc6-bab0-7621587291a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Baseline Jupyter.ipynb'   class-weights-improvement---03-0.89.hdf5\n",
      " baseline.py\t\t   training\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZOs3jTWGgM4Y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Baseline Jupyter.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
